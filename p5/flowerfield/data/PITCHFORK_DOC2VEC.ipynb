{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.0\n"
     ]
    }
   ],
   "source": [
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import smart_open\n",
    "import random\n",
    "import sqlite3\n",
    "import logging\n",
    "%matplotlib inline\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>00472b8e2d38d1ea</td>\n",
       "      <td>A pair of jew-hating weiner nazi schmucks.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>006b94add72ed61c</td>\n",
       "      <td>I think that your a Fagget get a oife and burn...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>008e0818dde894fb</td>\n",
       "      <td>Kill all niggers. \\n\\nI have hard, that others...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0097dd5c29bf7a15</td>\n",
       "      <td>u r a tw@ fuck off u gay boy.U r smelly.Fuck u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0           1  001810bf8c45bf5f   \n",
       "1           2  00472b8e2d38d1ea   \n",
       "2           3  006b94add72ed61c   \n",
       "3           4  008e0818dde894fb   \n",
       "4           5  0097dd5c29bf7a15   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  You are gay or antisemmitian? \\n\\nArchangel WH...      1             0   \n",
       "1         A pair of jew-hating weiner nazi schmucks.      1             0   \n",
       "2  I think that your a Fagget get a oife and burn...      1             0   \n",
       "3  Kill all niggers. \\n\\nI have hard, that others...      1             0   \n",
       "4  u r a tw@ fuck off u gay boy.U r smelly.Fuck u...      1             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        1       0       1              1  \n",
       "1        1       0       1              1  \n",
       "2        1       1       1              1  \n",
       "3        1       0       1              1  \n",
       "4        1       0       1              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=pd.read_csv('df_hatespeech.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(documents):\n",
    "    for i, text in enumerate(documents):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(text), [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(dataframe.comment_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['you', 'are', 'gay', 'or', 'antisemmitian', 'archangel', 'white', 'tiger', 'meow', 'greetingshhh', 'uh', 'there', 'are', 'two', 'ways', 'why', 'you', 'do', 'erased', 'my', 'comment', 'about', 'ww', 'that', 'holocaust', 'was', 'brutally', 'slaying', 'of', 'jews', 'and', 'not', 'gays', 'gypsys', 'slavs', 'anyone', 'if', 'you', 'are', 'anti', 'semitian', 'than', 'shave', 'your', 'head', 'bald', 'and', 'go', 'to', 'the', 'skinhead', 'meetings', 'if', 'you', 'doubt', 'words', 'of', 'the', 'bible', 'that', 'homosexuality', 'is', 'deadly', 'sin', 'make', 'pentagram', 'tatoo', 'on', 'your', 'forehead', 'go', 'to', 'the', 'satanistic', 'masses', 'with', 'your', 'gay', 'pals', 'first', 'and', 'last', 'warning', 'you', 'fucking', 'gay', 'won', 'appreciate', 'if', 'any', 'more', 'nazi', 'shwain', 'would', 'write', 'in', 'my', 'page', 'don', 'wish', 'to', 'talk', 'to', 'you', 'anymore', 'beware', 'of', 'the', 'dark', 'side'], tags=[0]),\n",
       " TaggedDocument(words=['pair', 'of', 'jew', 'hating', 'weiner', 'nazi', 'schmucks'], tags=[1])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "2019-02-27 12:00:20,296 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-02-27 12:00:20,301 : INFO : collecting all words and their counts\n",
      "2019-02-27 12:00:20,303 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-02-27 12:00:20,326 : INFO : collected 6326 word types and 1302 unique tags from a corpus of 1302 examples and 61950 words\n",
      "2019-02-27 12:00:20,329 : INFO : Loading a fresh vocabulary\n",
      "2019-02-27 12:00:20,344 : INFO : effective_min_count=2 retains 2715 unique words (42% of original 6326, drops 3611)\n",
      "2019-02-27 12:00:20,346 : INFO : effective_min_count=2 leaves 58339 word corpus (94% of original 61950, drops 3611)\n",
      "2019-02-27 12:00:20,364 : INFO : deleting the raw counts dictionary of 6326 items\n",
      "2019-02-27 12:00:20,366 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2019-02-27 12:00:20,368 : INFO : downsampling leaves estimated 39454 word corpus (67.6% of prior 58339)\n",
      "2019-02-27 12:00:20,387 : INFO : estimated required memory for 2715 words and 50 dimensions: 2703900 bytes\n",
      "2019-02-27 12:00:20,388 : INFO : resetting layer weights\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  if __name__ == '__main__':\n",
      "2019-02-27 12:00:20,461 : INFO : training model with 3 workers on 2715 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-27 12:00:20,549 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:20,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:20,562 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:20,563 : INFO : EPOCH - 1 : training on 61950 raw words (40753 effective words) took 0.1s, 421157 effective words/s\n",
      "2019-02-27 12:00:20,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:20,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:20,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:20,671 : INFO : EPOCH - 2 : training on 61950 raw words (40732 effective words) took 0.1s, 400305 effective words/s\n",
      "2019-02-27 12:00:20,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:20,794 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:20,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:20,799 : INFO : EPOCH - 3 : training on 61950 raw words (40903 effective words) took 0.1s, 338790 effective words/s\n",
      "2019-02-27 12:00:20,906 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:20,907 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:20,912 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:20,913 : INFO : EPOCH - 4 : training on 61950 raw words (40776 effective words) took 0.1s, 376623 effective words/s\n",
      "2019-02-27 12:00:21,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:21,017 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:21,022 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:21,023 : INFO : EPOCH - 5 : training on 61950 raw words (40819 effective words) took 0.1s, 392898 effective words/s\n",
      "2019-02-27 12:00:21,183 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:21,190 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:21,202 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:21,206 : INFO : EPOCH - 6 : training on 61950 raw words (40702 effective words) took 0.2s, 229461 effective words/s\n",
      "2019-02-27 12:00:21,375 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:21,379 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:21,381 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:21,382 : INFO : EPOCH - 7 : training on 61950 raw words (40819 effective words) took 0.2s, 260224 effective words/s\n",
      "2019-02-27 12:00:21,496 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:21,498 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:21,500 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:21,501 : INFO : EPOCH - 8 : training on 61950 raw words (40593 effective words) took 0.1s, 358386 effective words/s\n",
      "2019-02-27 12:00:21,614 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:21,620 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:21,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:21,624 : INFO : EPOCH - 9 : training on 61950 raw words (40654 effective words) took 0.1s, 344960 effective words/s\n",
      "2019-02-27 12:00:21,777 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:21,790 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:21,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:21,801 : INFO : EPOCH - 10 : training on 61950 raw words (40906 effective words) took 0.2s, 238715 effective words/s\n",
      "2019-02-27 12:00:21,949 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:21,965 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:21,969 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:21,972 : INFO : EPOCH - 11 : training on 61950 raw words (40725 effective words) took 0.2s, 248135 effective words/s\n",
      "2019-02-27 12:00:22,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:22,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:22,130 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:22,133 : INFO : EPOCH - 12 : training on 61950 raw words (40730 effective words) took 0.2s, 270571 effective words/s\n",
      "2019-02-27 12:00:22,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:22,314 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:22,316 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:22,322 : INFO : EPOCH - 13 : training on 61950 raw words (40699 effective words) took 0.2s, 221323 effective words/s\n",
      "2019-02-27 12:00:22,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:22,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:22,499 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:22,500 : INFO : EPOCH - 14 : training on 61950 raw words (40738 effective words) took 0.2s, 242470 effective words/s\n",
      "2019-02-27 12:00:22,609 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:22,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:22,640 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:22,641 : INFO : EPOCH - 15 : training on 61950 raw words (40766 effective words) took 0.1s, 306437 effective words/s\n",
      "2019-02-27 12:00:22,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:22,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:22,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:22,759 : INFO : EPOCH - 16 : training on 61950 raw words (40906 effective words) took 0.1s, 364615 effective words/s\n",
      "2019-02-27 12:00:22,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:22,896 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:22,897 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:22,898 : INFO : EPOCH - 17 : training on 61950 raw words (40805 effective words) took 0.1s, 308979 effective words/s\n",
      "2019-02-27 12:00:23,005 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:23,013 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:23,018 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:23,019 : INFO : EPOCH - 18 : training on 61950 raw words (40812 effective words) took 0.1s, 354272 effective words/s\n",
      "2019-02-27 12:00:23,145 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:23,165 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:23,171 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:23,172 : INFO : EPOCH - 19 : training on 61950 raw words (40688 effective words) took 0.1s, 277531 effective words/s\n",
      "2019-02-27 12:00:23,289 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:23,299 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:23,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:23,314 : INFO : EPOCH - 20 : training on 61950 raw words (40773 effective words) took 0.1s, 303027 effective words/s\n",
      "2019-02-27 12:00:23,424 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:23,428 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:23,430 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:23,431 : INFO : EPOCH - 21 : training on 61950 raw words (40859 effective words) took 0.1s, 376060 effective words/s\n",
      "2019-02-27 12:00:23,567 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:23,569 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:23,584 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:23,586 : INFO : EPOCH - 22 : training on 61950 raw words (40523 effective words) took 0.1s, 273230 effective words/s\n",
      "2019-02-27 12:00:23,693 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:23,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:23,703 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:23,704 : INFO : EPOCH - 23 : training on 61950 raw words (40747 effective words) took 0.1s, 359787 effective words/s\n",
      "2019-02-27 12:00:23,814 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:23,829 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:23,840 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:23,842 : INFO : EPOCH - 24 : training on 61950 raw words (40740 effective words) took 0.1s, 307554 effective words/s\n",
      "2019-02-27 12:00:23,955 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:23,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:23,969 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:23,970 : INFO : EPOCH - 25 : training on 61950 raw words (40681 effective words) took 0.1s, 344426 effective words/s\n",
      "2019-02-27 12:00:24,077 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:24,086 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:24,088 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:24,089 : INFO : EPOCH - 26 : training on 61950 raw words (40815 effective words) took 0.1s, 362066 effective words/s\n",
      "2019-02-27 12:00:24,201 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:24,204 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:24,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:24,209 : INFO : EPOCH - 27 : training on 61950 raw words (40724 effective words) took 0.1s, 366646 effective words/s\n",
      "2019-02-27 12:00:24,311 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:24,322 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:24,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:24,325 : INFO : EPOCH - 28 : training on 61950 raw words (40634 effective words) took 0.1s, 367996 effective words/s\n",
      "2019-02-27 12:00:24,426 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:24,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:24,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:24,436 : INFO : EPOCH - 29 : training on 61950 raw words (40823 effective words) took 0.1s, 388136 effective words/s\n",
      "2019-02-27 12:00:24,544 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:24,550 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:24,555 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:24,556 : INFO : EPOCH - 30 : training on 61950 raw words (40719 effective words) took 0.1s, 355910 effective words/s\n",
      "2019-02-27 12:00:24,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:24,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:24,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:24,679 : INFO : EPOCH - 31 : training on 61950 raw words (40796 effective words) took 0.1s, 347946 effective words/s\n",
      "2019-02-27 12:00:24,789 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:24,791 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:24,795 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:24,796 : INFO : EPOCH - 32 : training on 61950 raw words (40834 effective words) took 0.1s, 367755 effective words/s\n",
      "2019-02-27 12:00:24,899 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:24,904 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:24,911 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:24,914 : INFO : EPOCH - 33 : training on 61950 raw words (40698 effective words) took 0.1s, 370389 effective words/s\n",
      "2019-02-27 12:00:25,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:25,021 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:25,025 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:25,027 : INFO : EPOCH - 34 : training on 61950 raw words (40715 effective words) took 0.1s, 389593 effective words/s\n",
      "2019-02-27 12:00:25,131 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:25,145 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:25,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:25,148 : INFO : EPOCH - 35 : training on 61950 raw words (40660 effective words) took 0.1s, 352073 effective words/s\n",
      "2019-02-27 12:00:25,263 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:25,269 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:25,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:25,273 : INFO : EPOCH - 36 : training on 61950 raw words (40748 effective words) took 0.1s, 354970 effective words/s\n",
      "2019-02-27 12:00:25,387 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:25,393 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:25,401 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:25,402 : INFO : EPOCH - 37 : training on 61950 raw words (40662 effective words) took 0.1s, 327774 effective words/s\n",
      "2019-02-27 12:00:25,517 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:25,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:25,525 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:25,526 : INFO : EPOCH - 38 : training on 61950 raw words (40620 effective words) took 0.1s, 356579 effective words/s\n",
      "2019-02-27 12:00:25,636 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:25,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:25,648 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:25,649 : INFO : EPOCH - 39 : training on 61950 raw words (40763 effective words) took 0.1s, 347444 effective words/s\n",
      "2019-02-27 12:00:25,754 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:25,764 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:25,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:25,773 : INFO : EPOCH - 40 : training on 61950 raw words (40949 effective words) took 0.1s, 343926 effective words/s\n",
      "2019-02-27 12:00:25,882 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:25,891 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:25,892 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:25,893 : INFO : EPOCH - 41 : training on 61950 raw words (40879 effective words) took 0.1s, 363837 effective words/s\n",
      "2019-02-27 12:00:26,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:26,005 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:26,013 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:26,014 : INFO : EPOCH - 42 : training on 61950 raw words (40632 effective words) took 0.1s, 352446 effective words/s\n",
      "2019-02-27 12:00:26,124 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:26,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:26,143 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:26,144 : INFO : EPOCH - 43 : training on 61950 raw words (40871 effective words) took 0.1s, 332430 effective words/s\n",
      "2019-02-27 12:00:26,270 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:26,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:26,280 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:26,282 : INFO : EPOCH - 44 : training on 61950 raw words (40709 effective words) took 0.1s, 310189 effective words/s\n",
      "2019-02-27 12:00:26,425 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:26,436 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:26,461 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:26,462 : INFO : EPOCH - 45 : training on 61950 raw words (40888 effective words) took 0.2s, 238065 effective words/s\n",
      "2019-02-27 12:00:26,565 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:26,573 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:26,575 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:26,580 : INFO : EPOCH - 46 : training on 61950 raw words (40657 effective words) took 0.1s, 359861 effective words/s\n",
      "2019-02-27 12:00:26,702 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:26,726 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:26,728 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:26,729 : INFO : EPOCH - 47 : training on 61950 raw words (40838 effective words) took 0.1s, 295544 effective words/s\n",
      "2019-02-27 12:00:26,836 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:26,852 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:26,858 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:26,859 : INFO : EPOCH - 48 : training on 61950 raw words (40657 effective words) took 0.1s, 336110 effective words/s\n",
      "2019-02-27 12:00:26,970 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:26,972 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:26,979 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:26,980 : INFO : EPOCH - 49 : training on 61950 raw words (40660 effective words) took 0.1s, 355590 effective words/s\n",
      "2019-02-27 12:00:27,087 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:27,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:27,095 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:27,096 : INFO : EPOCH - 50 : training on 61950 raw words (40776 effective words) took 0.1s, 363809 effective words/s\n",
      "2019-02-27 12:00:27,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:27,207 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:27,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:27,213 : INFO : EPOCH - 51 : training on 61950 raw words (40884 effective words) took 0.1s, 366919 effective words/s\n",
      "2019-02-27 12:00:27,322 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:27,333 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:27,336 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:27,337 : INFO : EPOCH - 52 : training on 61950 raw words (40692 effective words) took 0.1s, 352052 effective words/s\n",
      "2019-02-27 12:00:27,441 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:27,444 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:27,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:27,451 : INFO : EPOCH - 53 : training on 61950 raw words (40790 effective words) took 0.1s, 379301 effective words/s\n",
      "2019-02-27 12:00:27,563 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:27,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:27,569 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:27,570 : INFO : EPOCH - 54 : training on 61950 raw words (40748 effective words) took 0.1s, 355980 effective words/s\n",
      "2019-02-27 12:00:27,678 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-27 12:00:27,687 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-27 12:00:27,688 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-27 12:00:27,690 : INFO : EPOCH - 55 : training on 61950 raw words (40804 effective words) took 0.1s, 361789 effective words/s\n",
      "2019-02-27 12:00:27,691 : INFO : training on a 3407250 raw words (2241494 effective words) took 7.2s, 310089 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.3 s, sys: 1.69 s, total: 11 s\n",
      "Wall time: 7.23 s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(size=50, min_count=2, epochs=55)\n",
    "model.build_vocab(train_corpus)\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18112677,  0.04341647,  0.2592071 ,  0.48513106, -0.16121829,\n",
       "       -0.14331356,  0.15535079,  0.24922524, -0.31270242, -0.14171124,\n",
       "        0.12851222, -0.08221748,  0.08571294, -0.37769493, -0.06415311,\n",
       "        0.0909925 , -0.08244795,  0.26329088, -0.4210768 ,  0.02762999,\n",
       "       -0.10760427, -0.21940836, -0.27469298,  0.02709269,  0.0164899 ,\n",
       "       -0.18721181, -0.14384638, -0.11059972, -0.17443605,  0.19040963,\n",
       "       -0.14513034, -0.00847333,  0.08921444, -0.13465998, -0.04013724,\n",
       "        0.19692846,  0.1032299 , -0.06237337,  0.02971481, -0.16189414,\n",
       "       -0.2033157 , -0.18498507,  0.00665316,  0.04867443, -0.2477462 ,\n",
       "       -0.12206189, -0.05252845, -0.37410653, -0.1541507 , -0.08361121],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-27 12:00:58,418 : INFO : precomputing L2-norms of doc weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1145, 0.9121553897857666),\n",
      " (26, 0.8520104289054871),\n",
      " (916, 0.8417160511016846),\n",
      " (501, 0.838097095489502),\n",
      " (544, 0.8259219527244568),\n",
      " (998, 0.8219479918479919),\n",
      " (1263, 0.81275475025177),\n",
      " (295, 0.8109985589981079),\n",
      " (52, 0.8003410696983337),\n",
      " (1244, 0.8000658750534058),\n",
      " (1103, 0.79949951171875),\n",
      " (1117, 0.794757068157196),\n",
      " (715, 0.7946627736091614),\n",
      " (999, 0.7884251475334167),\n",
      " (1246, 0.7881535291671753),\n",
      " (1270, 0.787699282169342),\n",
      " (910, 0.7870492339134216),\n",
      " (177, 0.7844111323356628),\n",
      " (953, 0.7841062545776367),\n",
      " (778, 0.783987283706665),\n",
      " (420, 0.7814779281616211),\n",
      " (896, 0.7812626361846924),\n",
      " (1133, 0.7782319784164429),\n",
      " (174, 0.7766663432121277),\n",
      " (1031, 0.7717846035957336),\n",
      " (634, 0.7708439826965332),\n",
      " (545, 0.7688124775886536),\n",
      " (1092, 0.7671576738357544),\n",
      " (1114, 0.7668066024780273),\n",
      " (435, 0.7659639716148376),\n",
      " (1205, 0.7655081152915955),\n",
      " (29, 0.7638734579086304),\n",
      " (251, 0.7630864381790161),\n",
      " (269, 0.76304692029953),\n",
      " (703, 0.7625434398651123),\n",
      " (565, 0.7592137455940247),\n",
      " (808, 0.7560951709747314),\n",
      " (138, 0.7553367018699646),\n",
      " (616, 0.7545672059059143),\n",
      " (723, 0.7521799802780151)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(model.docvecs.most_similar(positive=[1], topn=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint(model.docvecs.most_similar(positive=[\"philip glass\"], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint(model.docvecs.most_similar(positive=[\"gwen stefani\"], topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-27 12:01:37,336 : INFO : storing 1302x50 projection weights into doc_tensor_hate_speech.w2v\n"
     ]
    }
   ],
   "source": [
    "model.save_word2vec_format('doc_tensor_hate_speech.w2v', doctag_vec=True, word_vec=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-27 12:01:38,067 : INFO : saving Doc2Vec object under doc_tensor_hate_speech.doc2vec, separately None\n",
      "2019-02-27 12:01:38,136 : INFO : saved doc_tensor_hate_speech.doc2vec\n"
     ]
    }
   ],
   "source": [
    "model.save('doc_tensor_hate_speech.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-27 12:01:42,709 : INFO : loading Word2Vec object from doc_tensor_hate_speech.doc2vec\n",
      "2019-02-27 12:01:42,741 : INFO : loading vocabulary recursively from doc_tensor_hate_speech.doc2vec.vocabulary.* with mmap=None\n",
      "2019-02-27 12:01:42,743 : INFO : loading trainables recursively from doc_tensor_hate_speech.doc2vec.trainables.* with mmap=None\n",
      "2019-02-27 12:01:42,744 : INFO : loading wv recursively from doc_tensor_hate_speech.doc2vec.wv.* with mmap=None\n",
      "2019-02-27 12:01:42,746 : INFO : loading docvecs recursively from doc_tensor_hate_speech.doc2vec.docvecs.* with mmap=None\n",
      "2019-02-27 12:01:42,748 : INFO : loaded doc_tensor_hate_speech.doc2vec\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load('doc_tensor_hate_speech.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "model.docvecs.most_similar(positive=['rihanna', 'santigold'], negative=['gwen stefani'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(model.docvecs.most_similar(positive=['bob dylan'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = model.docvecs.similarity('jay z', 'kanye west') \n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = model.docvecs.similarity('bob dylan', 'kanye west') \n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = model.infer_vector(['a metal mean machine gears screeming black dark rock'])\n",
    "model.docvecs.most_similar(positive=[vec], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_vectors = model.docvecs.doctag_syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans( n_clusters = num_clusters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = kmeans_clustering.fit_predict( doc_vectors )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "word_centroid_list = list(zip(model.docvecs.offset2doctag, idx))\n",
    "word_centroid_list_sort = sorted(word_centroid_list, key=lambda el: el[1], reverse=False)\n",
    "for word_centroid in word_centroid_list_sort:\n",
    "    line = word_centroid[0] + '\\t' + str(word_centroid[1]) + '\\n'\n",
    "    print(line)\n",
    "    d.append({'artist': word_centroid[0], 'category': word_centroid[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[df['category'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " df['category'].value_counts().head(20).plot(title=\"Top Subreddits\", kind='bar', figsize=(15,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe.to_csv('pitchfork.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
